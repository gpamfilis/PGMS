{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from itertools import permutations\n",
    "from algorithms.hmm import ForwardBackwardAlgorithm\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from os import sys, path\n",
    "sys.path.append(path.dirname(path.dirname(path.abspath('__file__'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def elo_data_parser(elo_data_dir,p,team_pairs):\n",
    "    elo_h5 = h5py.File(elo_data_dir+'elo_pairs_'+str(p)+'.h5','r')\n",
    "    elo_data_home = elo_h5['pair_'+str(p)][team_pairs[p,0]][:].T\n",
    "    elo_data_away = elo_h5['pair_'+str(p)][team_pairs[p,1]][:].T\n",
    "    elo_df_home = pd.DataFrame(elo_data_home[:,1], index=elo_data_home[:,0].astype(int),columns=['elohome'])\n",
    "#     elo_df_home[0].plot()\n",
    "    elo_df_away = pd.DataFrame(elo_data_away[:,1], index=elo_data_away[:,0].astype(int),columns=['eloaway'])\n",
    "#     elo_df_away[1].plot()\n",
    "    elo_h5.close()\n",
    "    return elo_df_home, elo_df_away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transition_matrix_pxx(data, result, n_states=None):\n",
    "    \"\"\"\n",
    "    this method computes the transition matrix for single states NOT paired states.\n",
    "    \"\"\"\n",
    "    if n_states is None:\n",
    "        states = data[result].dropna().drop_duplicates().sort_values().astype(int).values\n",
    "    else:\n",
    "        states = range(n_states)\n",
    "    states_same_index = []\n",
    "    for state in states:\n",
    "        states_same_index.append((state, state))\n",
    "    data_df = data[result].dropna()\n",
    "    # stupid but works\n",
    "    transitions = [(int(i), int(j)) for i, j in list(permutations(states, 2)) + states_same_index]\n",
    "\n",
    "    transition_matrix = np.zeros((len(states), len(states)))\n",
    "    for index, transition in enumerate(transitions):\n",
    "        for i in range(data_df.shape[0]-1):\n",
    "            if (data_df.iloc[i], data_df.iloc[i + 1]) == transition:  # automatically create a tuple for multiple states\n",
    "                transition_matrix[transition] += 1\n",
    "    for state in states:\n",
    "        transition_matrix[state, :] = transition_matrix[state, :]/transition_matrix[state, :].sum()\n",
    "    return transition_matrix\n",
    "def emission_probabilities_pyx(ys, x_df, x_label='result_final', h_states=3):\n",
    "    un =  np.arange(-100,100.01,0.01).round(2)\n",
    "    pyx = np.zeros((h_states, un.shape[0]))\n",
    "#     print(un,pyx)\n",
    "    for i, ix in enumerate(ys.index):\n",
    "        try:\n",
    "            yx = np.where(ys[ix] == un)[0][0]\n",
    "            pyx[int(x_df.loc[ix][x_label]), int(yx)] += 1\n",
    "        except Exception as e:\n",
    "            # print(e)\n",
    "            continue\n",
    "    for i, s in enumerate(pyx.sum(axis=1)):\n",
    "        pyx[i, :] = pyx[i, :] / s\n",
    "    return pyx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onevsall(x,n):\n",
    "    if x==n:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_observed_data_elo_ratings = np.arange(-100,100.01,0.01).round(2)\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(unique_observed_data_elo_ratings);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_data = pd.read_csv('/home/kasper/Dropbox/DATA_SCORING/final_data_soccerway.csv', index_col='Unnamed: 0',parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_accuracies = []\n",
    "outputs = []\n",
    "global_classification_reports = []\n",
    "for date in ['2018-01-01','2018-01-02','2018-01-03','2018-01-04','2018-01-05']:\n",
    "    print(date)\n",
    "    # date = '2018-01-03'\n",
    "\n",
    "    elo_data_dir = '/home/kasper/PycharmProjects/scoring/DATA/'+date+'/elo_temp_goals/'\n",
    "    trueskill_data_dir = '/home/kasper/PycharmProjects/scoring/DATA/'+date+'/trueskill_temp/'\n",
    "    predict_file = '/home/kasper/PycharmProjects/scoring/DATA/'+date+'/'+date+'_predict_with_last_scores_ready_for_ml.csv'\n",
    "\n",
    "    result_key ='over_under_3.5'#'goal_no_goal'# str(n)+'vsA'\n",
    "#     result_key ='goal_no_goal'# str(n)+'vsA'\n",
    "#     result_key =str(0)+'vsA'\n",
    "\n",
    "    n_states = 2\n",
    "    prediction_df = pd.read_csv(predict_file, index_col='Unnamed: 0')\n",
    "    # prediction_df =prediction_df.dropna(subset=[result_key])\n",
    "    prediction_df.loc[:,'date'] = date\n",
    "    prediction_df.loc[:,'date'] = pd.to_datetime(prediction_df.date)\n",
    "    for n in [0,1,2]:\n",
    "        prediction_df.loc[:,str(n)+'vsA'] = prediction_df['result_final'].apply(onevsall,args=(n,))\n",
    "\n",
    "    team_pairs = prediction_df[['home_team','away_team']].values\n",
    "    htdf = prediction_df[['EH',result_key,'result_final','date']]\n",
    "    htdf.columns = ['elohome',result_key,'result_final','date']\n",
    "    atdf = prediction_df[['EA',result_key,'result_final','date']]\n",
    "    atdf.columns = ['eloaway',result_key,'result_final','date']\n",
    "\n",
    "    accuracies = []\n",
    "    ps = []\n",
    "    classification_reports = []\n",
    "    ytrue = []\n",
    "    ypreds = []\n",
    "    for pix, pair in enumerate(team_pairs[:]):\n",
    "#         result_key ='over_under_1.5'#'goal_no_goal'# str(n)+'vsA'\n",
    "\n",
    "        p = prediction_df.iloc[pix].name\n",
    "        try:\n",
    "#             print(p)\n",
    "            eloH, eloA = elo_data_parser(elo_data_dir,p,team_pairs)\n",
    "            eloH.loc[:,result_key] = game_data.loc[eloH.index][result_key]\n",
    "            eloA.loc[:,result_key] = game_data.loc[eloA.index][result_key]\n",
    "            eloH.loc[:,'date'] = game_data.loc[eloH.index]['date']\n",
    "            eloA.loc[:,'date'] = game_data.loc[eloA.index]['date']\n",
    "\n",
    "            if (eloH.shape[0]<=70) | (eloA.shape[0]<=70):\n",
    "                print('low_lim')\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "        acs = []\n",
    "        creps = []\n",
    "        yps = []\n",
    "        try:\n",
    "            eloH.loc[:,'result_final'] = game_data.loc[eloH.index]['result_final']\n",
    "            eloA.loc[:,'result_final'] = game_data.loc[eloA.index]['result_final']\n",
    "        except:\n",
    "            continue\n",
    "    #     print(eloH.tail())\n",
    "        elo_df_home = pd.concat([eloH,htdf.iloc[p].to_frame().T],axis=0)\n",
    "        elo_df_away = pd.concat([eloA,atdf.iloc[p].to_frame().T],axis=0)\n",
    "    #     print(elo_df_home.tail())\n",
    "        for n in [0,1,2]:\n",
    "            elo_df_home.loc[:, str(n)+'vsA'] = elo_df_home['result_final'].apply(onevsall,args=(n,))\n",
    "            elo_df_away.loc[:, str(n)+'vsA'] = elo_df_away['result_final'].apply(onevsall,args=(n,))\n",
    "    #     print(elo_df_home.tail())\n",
    "\n",
    "        elo_df_home.loc[:,'elohome'] = elo_df_home.loc[:,'elohome'].diff().fillna(method='ffill').replace(np.nan,0).round(2)\n",
    "        elo_df_away.loc[:,'eloaway'] = elo_df_away.loc[:,'eloaway'].diff().fillna(method='ffill').replace(np.nan,0).round(2)\n",
    "    #     print(elo_df_home.tail())\n",
    "\n",
    "        elo_df_home = elo_df_home.dropna()\n",
    "        elo_df_away = elo_df_away.dropna()\n",
    "    #     print(elo_df_home.tail())\n",
    "\n",
    "        elo_df_sides = {'elohome':elo_df_home,'eloaway':elo_df_away}\n",
    "\n",
    "        for side in ['elohome','eloaway']:\n",
    "#             result_key =str(0)+'vsA'\n",
    "\n",
    "            elo_df = elo_df_sides[side]\n",
    "            elo_df[elo_df['date']>elo_df.iloc[-1].date-datetime.timedelta(2*365)]\n",
    "\n",
    "            elo_df_train = elo_df.iloc[:-1]\n",
    "            elo_df_test = elo_df.iloc[-1:]\n",
    "\n",
    "            px = elo_df_train[result_key].value_counts(normalize=True).sort_index().values\n",
    "            pxx = transition_matrix_pxx(data=elo_df_train, result=result_key, n_states=n_states)\n",
    "            pyx = emission_probabilities_pyx(ys=elo_df_train[side], x_df=elo_df_train, x_label=result_key, h_states=n_states)\n",
    "\n",
    "            try:\n",
    "                transformed_observed_data_elo_ratings = le.transform(elo_df_test[side].values)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                fba = ForwardBackwardAlgorithm(px, pxx, pyx, transformed_observed_data_elo_ratings)\n",
    "                forward = fba.forward()\n",
    "                backward = fba.backward()\n",
    "                gammas = fba.gammas()\n",
    "                truth = elo_df_test[result_key].values.astype(int)\n",
    "                prophet = np.argmax(gammas,axis=1)\n",
    "                ac = metrics.accuracy_score(truth, prophet)\n",
    "                crep = metrics.classification_report(truth, prophet)\n",
    "                yp = prophet[-1]\n",
    "\n",
    "            except Exception as e:\n",
    "                print('shit')\n",
    "                print(e)\n",
    "                continue\n",
    "            acs.append(ac)\n",
    "            yps.append(yp)\n",
    "\n",
    "            creps.append(crep)\n",
    "            \n",
    "        ps.append(p)\n",
    "        ypreds.append(yps)\n",
    "        classification_reports.append(creps)\n",
    "        accuracies.append(acs)\n",
    "        ytrue.append(elo_df_test[result_key].iloc[-1])\n",
    "\n",
    "\n",
    "    yt = np.array(ytrue)\n",
    "    yp = np.array([yp[0] for yp in ypreds])\n",
    "    output = pd.DataFrame(list(zip(yp,yt)),index=ps)\n",
    "    outputs.append(output)\n",
    "#     output = output[output[0]!=0]\n",
    "    yt = output[1].values\n",
    "    yp = output[0].values\n",
    "    global_accuracies.append(metrics.accuracy_score(yt,yp))\n",
    "    global_classification_reports.append(metrics.classification_report(yt,yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trueskill_data = h5py.File(trueskill_data_dir+'trueskill_pairs_'+str(p)+'.h5','r')\n",
    "\n",
    "pd.DataFrame(trueskill_data['pair_'+str(p)][team_pairs[p,0]][:].T)[1].plot()\n",
    "\n",
    "pd.DataFrame(trueskill_data['pair_'+str(p)][team_pairs[p,1]][:].T)[1].plot()\n",
    "trueskill_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(trueskill_data['pair_'+str(p)][team_pairs[p,0]][:].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "\n",
    "states = [\"Rainy\", \"Sunny\"]\n",
    "n_states = len(states)\n",
    "\n",
    "observations = [\"walk\", \"shop\", \"clean\"]\n",
    "n_observations = len(observations)\n",
    "\n",
    "model = hmm.MultinomialHMM(n_components=n_states, init_params=\"\")\n",
    "model.startprob_ = np.array([0.6, 0.4])\n",
    "model.transprob_ = np.array([[0.7, 0.3],[0.4, 0.6]])\n",
    "model.emissionprob_ = np.array([[0.1, 0.4, 0.5],\n",
    "                                [0.6, 0.3, 0.1]])\n",
    "# predict a sequence of hidden states based on visible states\n",
    "bob_says = np.array([[0,1,2]]).T#, 1, 1, 2, 0,1,1]]).T\n",
    "\n",
    "model = model.fit(bob_says)\n",
    "logprob, alice_hears = model.decode(bob_says, algorithm=\"viterbi\")\n",
    "print(\"Bob said:\", \", \".join(map(lambda x: observations[int(x)], bob_says)))\n",
    "print(\"Alice Believes:\", \", \".join(map(lambda x: states[x], alice_hears)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
