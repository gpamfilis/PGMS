{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import sys, path\n",
    "sys.path.append(path.dirname(path.dirname(path.abspath('__file__'))))\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/38601026/easy-way-to-use-parallel-options-of-scikit-learn-functions-on-hpc/38814491#38814491"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasper/PycharmProjects/venv/lib/python3.5/site-packages/numpy/lib/arraysetops.py:466: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/home/kasper/Dropbox/Scrapping/soccerway/csv/final_data_soccerway.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = pd.read_csv('../data/predict.csv', index_col='Unnamed: 0')\n",
    "df_teams = pred_data[['home_team','away_team']].values\n",
    "final = pd.read_csv('./final.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ht = final.home_team.values\n",
    "at = final.away_team.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_teams = np.append(ht,at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "un = np.unique(all_teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.loc[:,'home_team'] = le.transform(final.home_team.values)\n",
    "final.loc[:,'away_team'] = le.transform(final.away_team.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>res_index</th>\n",
       "      <th>EH</th>\n",
       "      <th>EA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2301</td>\n",
       "      <td>610</td>\n",
       "      <td>2133</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1599</td>\n",
       "      <td>1598</td>\n",
       "      <td>2134</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5195</td>\n",
       "      <td>4651</td>\n",
       "      <td>2135</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1026</td>\n",
       "      <td>1701</td>\n",
       "      <td>2137</td>\n",
       "      <td>90.143872</td>\n",
       "      <td>109.856128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3310</td>\n",
       "      <td>2811</td>\n",
       "      <td>2163</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   home_team  away_team  res_index          EH          EA\n",
       "0       2301        610       2133  100.000000  100.000000\n",
       "1       1599       1598       2134  100.000000  100.000000\n",
       "2       5195       4651       2135  100.000000  100.000000\n",
       "3       1026       1701       2137   90.143872  109.856128\n",
       "4       3310       2811       2163  105.000000   95.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_index = final.res_index.values\n",
    "out = df.loc[res_index]\n",
    "result_key = 'result_final' \n",
    "final.loc[:, result_key] = out[result_key].values\n",
    "final = final.dropna()\n",
    "final2 = final.drop('res_index', axis=1)\n",
    "final2.to_csv('./final_trans.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "del ht,at,un,all_teams,le,final,final2,res_index,out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final = pd.read_csv('./final_trans.csv', index_col='Unnamed: 0')\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_out_100(data):\n",
    "    print('[Filter]')\n",
    "    dataf = data[(data.EH!=100) & (data.EA!=100)].iloc[:]\n",
    "    return dataf\n",
    "\n",
    "def plot_data_labels(data, labels=['1','X','2'], npoints=1000):\n",
    "    x = data.iloc[:npoints]['EH'].values\n",
    "    y = data.iloc[:npoints]['EA'].values\n",
    "    label = data.iloc[:npoints][result_key].values\n",
    "    colors = ['green','blue','black']\n",
    "\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    plt.scatter(x, y, c=label, cmap=matplotlib.colors.ListedColormap(colors))\n",
    "    plt.xlabel('EH')\n",
    "    plt.ylabel('EA')\n",
    "    cb = plt.colorbar()\n",
    "    loc = np.arange(0,max(label),max(label)/float(len(colors)))\n",
    "    cb.set_ticks(loc)\n",
    "    cb.set_ticklabels(labels)\n",
    "    return data\n",
    "\n",
    "def run_pca(data):\n",
    "    print('[PCA]')\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "\n",
    "    # print(pca.explained_variance_ratio_)  \n",
    "\n",
    "    # print(pca.singular_values_)  \n",
    "\n",
    "    pca.fit(data.values[:,[2,3]])\n",
    "\n",
    "    tx =  pca.transform(data.values[:,[2,3]]) \n",
    "\n",
    "    data.loc[:,['EH','EA']] = tx\n",
    "    return data\n",
    "\n",
    "def classify(data):\n",
    "    print(data.head())\n",
    "    print('[Classifier]')\n",
    "    X = data.iloc[:][['home_team','away_team','EH','EA']]#.values\n",
    "    # X = final.iloc[:][['EH','EA']]#.values\n",
    "    y = data.iloc[:][result_key]#.values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.75, test_size=0.25, random_state=42)\n",
    "\n",
    "    # final.iloc[:50000].tail()\n",
    "\n",
    "    clf = GaussianNB()\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "\n",
    "    print('Accuracy: ',clf.score(X_test, y_test))\n",
    "    # print(metrics.accuracy_score(clf.predict(X_test), y_test))\n",
    "    # clf.export('tpot_mnist_pipeline.py')\n",
    "\n",
    "    predictions = clf.predict(X_test)\n",
    "\n",
    "    pprint.pprint(metrics.classification_report(predictions, y_test))\n",
    "\n",
    "#     predicted = cross_val_predict(clf, X,y, cv=5)\n",
    "    return data\n",
    "\n",
    "def pipeline_func(data, fns):\n",
    "    return reduce(lambda a,x: x(a), fns, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING SECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fd = run_pca(filter_out_100(final2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = fd.iloc[:][['home_team','away_team','EH','EA']]#.values\n",
    "y = fd.iloc[:][result_key]#.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from distributed.joblib import DistributedBackend \n",
    "\n",
    "# it is important to import joblib from sklearn if we want the distributed features to work with sklearn!\n",
    "from sklearn.externals.joblib import Parallel, parallel_backend, register_parallel_backend\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "weights = ['distance','uniform']\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=5,weights=weights[0])\n",
    "\n",
    "from IPython.parallel import Client\n",
    "ipclient = Client(profile='ssh')\n",
    "\n",
    "e = ipclient.become_dask()\n",
    "\n",
    "e\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.75, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "register_parallel_backend('distributed', DistributedBackend)\n",
    "\n",
    "%time\n",
    "with parallel_backend('distributed', scheduler_host='192.168.0.101:42434'):\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "%time\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "X.shape\n",
    "\n",
    "pprint.pprint(metrics.accuracy_score(y_pred, y_test))\n",
    "pprint.pprint(metrics.classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NO CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.75, test_size=0.25, random_state=42)\n",
    "accs=[]\n",
    "clfs = []\n",
    "weights = ['distance','uniform']\n",
    "max_nei = 5\n",
    "for w in weights:\n",
    "    print(w)\n",
    "    acc = []\n",
    "    for n in range(1,max_nei):\n",
    "        print(n)\n",
    "        clf = KNeighborsClassifier(n_neighbors=n,weights=w)\n",
    "        clf.fit(X_train, y_train) \n",
    "        acc.append(clf.score(X_test, y_test))\n",
    "    accs.append(acc)\n",
    "\n",
    "for w, a in enumerate(accs):\n",
    "    plt.plot(range(1,max_nei), a, label=weights[w])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with cv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "accs=[]\n",
    "clfs = []\n",
    "weights = ['distance','uniform']\n",
    "max_nei = 10\n",
    "for w in weights:\n",
    "    print(w)\n",
    "    acc = []\n",
    "    for n in range(1,max_nei):\n",
    "        print(n)\n",
    "        clf = KNeighborsClassifier(n_neighbors=n,weights=w)\n",
    "        predicted = cross_val_predict(clf, X, y, cv=5)\n",
    "        acc.append(metrics.accuracy_score(predicted , y))\n",
    "\n",
    "    accs.append(acc)\n",
    "\n",
    "for w, a in enumerate(accs):\n",
    "    plt.plot(range(1,max_nei), a, label=weights[w])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.75, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = ['distance','uniform']\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=5,weights=weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "X.shape\n",
    "\n",
    "pprint.pprint(metrics.accuracy_score(y_pred, y_test))\n",
    "pprint.pprint(metrics.classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAUSSIAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fns = [classify]\n",
    "out = pipeline_func(fd,fns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf2 = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.1, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf2 = clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions2 = clf2.predict(X_test)\n",
    "pprint.pprint(metrics.classification_report(y_test, predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fns = [filter_out_100,plot_data_labels, classify, run_pca, plot_data_labels, classify]\n",
    "# fns = [filter_out_100,plot_data_labels, run_pca, plot_data_labels]\n",
    "\n",
    "\n",
    "data = filter_out_100(final)\n",
    "\n",
    "clf1 = GaussianNB()\n",
    "\n",
    "X = data.iloc[:][['home_team','away_team','EH','EA']]#.values\n",
    "# X = final.iloc[:][['EH','EA']]#.values\n",
    "y = data.iloc[:][result_key]#.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.75, test_size=0.25, random_state=42)\n",
    "\n",
    "# final.iloc[:50000].tail()\n",
    "\n",
    "# clf = GaussianNB()\n",
    "clf1 = clf1.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy: ',clf1.score(X_test, y_test))\n",
    "# print(metrics.accuracy_score(clf.predict(X_test), y_test))\n",
    "# clf.export('tpot_mnist_pipeline.py')\n",
    "\n",
    "predictions1 = clf1.predict(X_test)\n",
    "pprint.pprint(metrics.classification_report(predictions1, y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data1 = run_pca(data)\n",
    "\n",
    "final.head()\n",
    "\n",
    "data.head()\n",
    "\n",
    "X = data1.iloc[:][['home_team','away_team','EH','EA']]#.values\n",
    "# X = final.iloc[:][['EH','EA']]#.values\n",
    "y = data1.iloc[:][result_key]#.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.75, test_size=0.25, random_state=42)\n",
    "\n",
    "# final.iloc[:50000].tail()\n",
    "\n",
    "# clf = GaussianNB()\n",
    "clf2 = clf2.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy: ',clf2.score(X_test, y_test))\n",
    "# print(metrics.accuracy_score(clf.predict(X_test), y_test))\n",
    "# clf.export('tpot_mnist_pipeline.py')\n",
    "\n",
    "predictions2 = clf2.predict(X_test)\n",
    "pprint.pprint(metrics.classification_report(predictions2, y_test))\n",
    "\n",
    "def choose(p1,p2, key=[0,0]):\n",
    "    if p1==key[0]:\n",
    "        return p1\n",
    "    elif p2==key[1]:\n",
    "        return p2\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "output_df = pd.DataFrame(list(zip(predictions1,predictions2, y_test)), columns=['p1','p2','ytrue'])\n",
    "\n",
    "out1 = []\n",
    "for i, (ix, row) in enumerate(output_df.iterrows()):\n",
    "    out1.append(choose(row.p1,row.p2, key=[0, 0]))\n",
    "\n",
    "out2 = []\n",
    "for i, (ix, row) in enumerate(output_df.iterrows()):\n",
    "    out2.append(choose(row.p1,row.p2,key=[1, 1]))\n",
    "\n",
    "output_df.loc[:, 'fil1'] = out1\n",
    "\n",
    "output_df.loc[:, 'fil2'] = out2\n",
    "\n",
    "fi3 = output_df[['fil1', 'fil2']].sum(axis=1).values.astype(int)\n",
    "\n",
    "output_df.loc[:,'fil3'] = fi3\n",
    "\n",
    "\n",
    "\n",
    "output_df['fil3'].value_counts()\n",
    "output_df[['fil1', 'fil2']].sum(axis=1).value_counts()\n",
    "\n",
    "\n",
    "\n",
    "print(output_df.shape)\n",
    "output_df = output_df.dropna()\n",
    "print(output_df.shape)\n",
    "\n",
    "print(metrics.accuracy_score(output_df['fil3'].values.astype(int), output_df['ytrue'].values.astype(int)))\n",
    "\n",
    "ytrue = output_df['ytrue'].values.astype(int)\n",
    "fi = output_df['fil3'].values.astype(int)\n",
    "\n",
    "pprint.pprint(metrics.classification_report(fi, ytrue))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "metrics.accuracy_score()\n",
    "\n",
    "output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# print(pca.explained_variance_ratio_)  \n",
    "\n",
    "# print(pca.singular_values_)  \n",
    "\n",
    "pca.fit(final2.values[:,[2,3]])\n",
    "\n",
    "tx =  pca.transform(final2.values[:,[2,3]]) \n",
    "\n",
    "final2.loc[:,['EH','EA']] = tx\n",
    "\n",
    "\n",
    "\n",
    "x = final2['EH'].values\n",
    "y = final2['EA'].values\n",
    "label = final2['over_under_2.5'].values\n",
    "colors = ['green','black']\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.scatter(x, y, c=label, cmap=matplotlib.colors.ListedColormap(colors))\n",
    "plt.xlabel('EH')\n",
    "plt.ylabel('EA')\n",
    "cb = plt.colorbar()\n",
    "loc = np.arange(0,max(label),max(label)/float(len(colors)))\n",
    "cb.set_ticks(loc)\n",
    "cb.set_ticklabels(['over','under'])\n",
    "\n",
    "final2.head(2)\n",
    "\n",
    "\n",
    "\n",
    "final2['C_sign'] = np.sign(final2.EH)\n",
    "final2.groupby('over_under_3.5').C_sign.value_counts()\n",
    "\n",
    "### NO PCA\n",
    "\n",
    "final2 = final[(final.EH!=100) | (final.EA!=100)].iloc[:20000]\n",
    "\n",
    "final2.shape\n",
    "\n",
    "\n",
    "X = final2.iloc[:][['home_team','away_team','EH','EA']]#.values\n",
    "# X = final.iloc[:][['EH','EA']]#.values\n",
    "y = final2.iloc[:]['over_under_2.5']#.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.75, test_size=0.25, random_state=42)\n",
    "\n",
    "# final.iloc[:50000].tail()\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy: ',clf.score(X_test, y_test))\n",
    "# print(metrics.accuracy_score(clf.predict(X_test), y_test))\n",
    "# clf.export('tpot_mnist_pipeline.py')\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "pprint.pprint(metrics.classification_report(predictions, y_test))\n",
    "\n",
    "predicted = cross_val_predict(clf, X,y, cv=5)\n",
    "\n",
    "# metrics.precision_score(y, predicted,pos_label=1) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# with pca\n",
    "\n",
    "final2['over_under_2.5'].value_counts(normalize=False).sort_index()\n",
    "\n",
    "final2.shape\n",
    "\n",
    "final2 = final[(final.EH!=100) | (final.EA!=100)].iloc[:20000]\n",
    "\n",
    "pca.fit(final2.values[:,[2,3]])\n",
    "\n",
    "tx =  pca.transform(final2.values[:,[2,3]]) \n",
    "\n",
    "final2.loc[:,['EH','EA']] = tx\n",
    "\n",
    "X = final2.iloc[:][['home_team','away_team','EH','EA']]#.values\n",
    "# X = final.iloc[:][['EH','EA']]#.values\n",
    "y = final2.iloc[:]['over_under_2.5']#.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.75, test_size=0.25, random_state=42)\n",
    "\n",
    "# final.iloc[:50000].tail()\n",
    "\n",
    "clf = GaussianNB()\n",
    "\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy: ',clf.score(X_test, y_test))\n",
    "\n",
    "# clf.export('tpot_mnist_pipeline.py')\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "pprint.pprint(metrics.classification_report(predictions, y_test))\n",
    "\n",
    "X = final2.iloc[:][['home_team','away_team','EH','EA']]#.values\n",
    "# X = final.iloc[:][['EH','EA']]#.values\n",
    "y = final2.iloc[:]['over_under_2.5']#.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.75, test_size=0.25, random_state=42)\n",
    "\n",
    "# final.iloc[:50000].tail()\n",
    "\n",
    "tpot = TPOTClassifier(generations=1, population_size=13, verbosity=2)\n",
    "\n",
    "clf = tpot.fit(X_train, y_train)\n",
    "\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "clf.export('tpot_mnist_pipeline.py')\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "pprint.pprint(metrics.classification_report(predictions, y_test))\n",
    "\n",
    "X = final2.iloc[:][['home_team','away_team','EH','EA']]#.values\n",
    "# X = final.iloc[:][['EH','EA']]#.values\n",
    "y = final2.iloc[:]['over_under_2.5']#.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.75, test_size=0.25, random_state=42)\n",
    "\n",
    "# final.iloc[:50000].tail()\n",
    "\n",
    "tpot = TPOTClassifier(generations=1, population_size=13, verbosity=2)\n",
    "\n",
    "clf = GaussianNB().fit(X_train, y_train)\n",
    "\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "clf.export('tpot_mnist_pipeline.py')\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "pprint.pprint(metrics.classification_report(predictions, y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# %load tpot_mnist_pipeline.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# NOTE: Make sure that the class is labeled 'target' in the data file\n",
    "tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)\n",
    "features = tpot_data.drop('target', axis=1).values\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, tpot_data['target'].values, random_state=42)\n",
    "\n",
    "# Score on the training set was:0.5814399904848592\n",
    "exported_pipeline = KNeighborsClassifier(n_neighbors=69, p=2, weights=\"distance\")\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "# X = final.iloc[:50000][['home_team','away_team','EH','EA']]#.values\n",
    "# # X = final.iloc[:][['EH','EA']]#.values\n",
    "# y = final.iloc[:50000]['over_under_2.5']#.values\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.75, test_size=0.25, random_state=42)\n",
    "\n",
    "clf1 = GaussianNB()\n",
    "clf1.fit(X_train, y_train)\n",
    "print(clf1.score(X_test, y_test))\n",
    "predictions1 = clf1.predict(X_test)\n",
    "\n",
    "pprint.pprint(metrics.classification_report(predictions1, y_test))\n",
    "\n",
    "\n",
    "\n",
    "print(clf2.score(X_test, y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# %load tpot_mnist_pipeline.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# NOTE: Make sure that the class is labeled 'target' in the data file\n",
    "tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)\n",
    "features = tpot_data.drop('target', axis=1).values\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, tpot_data['target'].values, random_state=42)\n",
    "\n",
    "# Score on the training set was:0.5522662309923989\n",
    "exported_pipeline = GaussianNB()\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = final.iloc[:10000][['home_team','away_team','EH','EA']]#.values\n",
    "y = final.iloc[:10000]['over_under_2.5']#.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.75, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "# Add noisy features\n",
    "random_state = np.random.RandomState(0)\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "# Create a simple classifier\n",
    "classifier = svm.LinearSVC(random_state=random_state)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_score = classifier.decision_function(X_test)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_score,pos_label=0)\n",
    "\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                 color='b')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 0.2])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision))\n",
    "predictions = tpot.predict_proba(X_test)\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "from sklearn.preprocessing import label_binarize\n",
    "# Binarize the output\n",
    "y = label_binarize(y, classes=[0, 1])\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "# Add noisy features to make the problem harder\n",
    "\n",
    "y_score = clf.decision_function(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "aa = pd.DataFrame(list(zip(predictions,y_test)))\n",
    "\n",
    "a = pd.DataFrame(y_train)\n",
    "a['over_under_2.5'].value_counts(normalize=True).sort_index()\n",
    "\n",
    "ys = aa[aa[0]!=0].values\n",
    "\n",
    "yp = ys[:,0]\n",
    "yt = ys[:,1]\n",
    "\n",
    "pprint.pprint(metrics.classification_report(yp, yt))\n",
    "\n",
    "# %load tpot_mnist_pipeline.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# NOTE: Make sure that the class is labeled 'target' in the data file\n",
    "tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)\n",
    "features = tpot_data.drop('target', axis=1).values\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, tpot_data['target'].values, random_state=42)\n",
    "\n",
    "# Score on the training set was:0.5523999202370016\n",
    "exported_pipeline = GaussianNB()\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "\n",
    "X = final.iloc[:][['home_team','away_team','EH','EA']].values\n",
    "y = final.iloc[:]['over_under_2.5'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.75, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "gbm = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.1)\n",
    "\n",
    "gbm.fit(X_train, y_train)\n",
    "\n",
    "predictions = gbm.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "pprint.pprint(metrics.classification_report(predictions, y_test))\n",
    "\n",
    "ac = metrics.accuracy_score(predictions, y_test)\n",
    "\n",
    "print(ac)\n",
    "\n",
    "metrics.confusion_matrix(predictions, y_test)\n",
    "\n",
    "\n",
    "conf_arr = metrics.confusion_matrix(predictions, y_test)\n",
    "\n",
    "norm_conf = []\n",
    "for i in conf_arr:\n",
    "    a = 0\n",
    "    tmp_arr = []\n",
    "    a = sum(i, 0)\n",
    "    for j in i:\n",
    "        tmp_arr.append(float(j)/float(a))\n",
    "    norm_conf.append(tmp_arr)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.clf()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_aspect(1)\n",
    "res = ax.imshow(np.array(norm_conf), cmap=plt.cm.jet, \n",
    "                interpolation='nearest')\n",
    "\n",
    "width, height = conf_arr.shape\n",
    "\n",
    "for x in range(width):\n",
    "    for y in range(height):\n",
    "        ax.annotate(str(conf_arr[x][y]), xy=(y, x), \n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center')\n",
    "\n",
    "cb = fig.colorbar(res)\n",
    "alphabet1 = ['Predicted-O','Predicted-U']\n",
    "alphabet2 = ['Actual-O','Actual-U']\n",
    "plt.xticks(range(width), alphabet2[:width])\n",
    "plt.yticks(range(height), alphabet1[:height])\n",
    "plt.savefig('confusion_matrix.png', format='png')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "digits = load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target,\n",
    "                                                    train_size=0.75, test_size=0.25)\n",
    "\n",
    "digits.data\n",
    "\n",
    "digits.target\n",
    "\n",
    "tpot = TPOTClassifier(generations=5, population_size=20, verbosity=2)\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "elohome\n",
    "\n",
    "ar_data[0].astype(int)\n",
    "\n",
    "dfs[1]\n",
    "\n",
    "ar_data = h5f[champ][team][:].T[r]\n",
    "\n",
    "ar_data\n",
    "\n",
    "tot = pd.concat(dfs, axis=0, ignore_index=False)\n",
    "\n",
    "tot\n",
    "\n",
    "h5f.close()\n",
    "\n",
    "len(outcomes)\n",
    "\n",
    "ypred\n",
    "metrics.recall_score(y_pred=ypred, y_true=ytrue, pos_label=0)\n",
    "\n",
    "ypred\n",
    "\n",
    "ytrue\n",
    "transformed_observed_data_elo_ratings.shape\n",
    "\n",
    "bob_says = transformed_observed_data_elo_ratings.reshape(-1,1)[-470:]\n",
    "model = model.fit(bob_says)\n",
    "transformed_observed_data_elo_ratings.reshape(-1, 1)[-10:]\n",
    "\n",
    "bob_says\n",
    "\n",
    "h5f.close()\n",
    "\n",
    "print(\"Bob said:\", \", \".join(map(lambda x: observations[int(x)], bob_says)))\n",
    "print(\"Alice Believes:\", \", \".join(map(lambda x: states[x], alice_hears)))\n",
    "h5f.close()\n",
    "pxx = transition_matrix_pxx(data=df.loc[htd.index]['result_final'].dropna().to_frame(),result='result_final',n_states=3)\n",
    "\n",
    "pyx = emission_probabilities_pyx(x_df=df.loc[htd.index]['result_final'].dropna().to_frame(),x_label='result_final',hidden_states=3,y_df=htd)\n",
    "\n",
    "px = df.loc[htd.index]['result_final'].value_counts(normalize=True).sort_index()\n",
    "\n",
    "px\n",
    "\n",
    "pxx\n",
    "\n",
    "\n",
    "df.loc[htd.index]['result_final'].dropna().to_frame()\n",
    "\n",
    "a = df[((df.home_team==teamh) & (df.away_team==teama)) | ((df.home_team==teama)&(df.away_team==teamh))]\n",
    "\n",
    "a\n",
    "\n",
    "l = pd.concat([ht,at],axis=1)\n",
    "\n",
    "l.plot()\n",
    "# l.loc[a.index].plot()\n",
    "\n",
    "pd.concat([htd,atd],axis=1).plot()\n",
    "\n",
    "pd.concat([ht,at],axis=1).plot()\n",
    "\n",
    "ht.plot()\n",
    "at.plot()\n",
    "\n",
    "# df.loc[995088]\n",
    "\n",
    "# df[((df.home_team==teams[i]) | (df.away_team==teams[i])) & (df.championship==champ)]\n",
    "\n",
    "# df.loc[2054071]\n",
    "\n",
    "import itertools\n",
    "import math\n",
    "import trueskill\n",
    "def win_probability(team1, team2):\n",
    "    delta_mu = sum(r.mu for r in team1) - sum(r.mu for r in team2)\n",
    "    sum_sigma = sum(r.sigma ** 2 for r in itertools.chain(team1, team2))\n",
    "    size = len(team1) + len(team2)\n",
    "    denom = math.sqrt(size * (BETA * BETA) + sum_sigma)\n",
    "    ts = trueskill.global_env()\n",
    "    return ts.cdf(delta_mu / denom)\n",
    "\n",
    "BETA = ts.BETA\n",
    "def win_probability(a, b):                                                      \n",
    "    deltaMu = sum([x.mu for x in a]) - sum([x.mu for x in b])                   \n",
    "    sumSigma = sum([x.sigma ** 2 for x in a]) + sum([x.sigma ** 2 for x in b])  \n",
    "    playerCount = len(a) + len(b)                                               \n",
    "    denominator = math.sqrt(playerCount * (BETA * BETA) + sumSigma)             \n",
    "    return cdf(deltaMu / denominator)  \n",
    "\n",
    "teams = np.arange(100)\n",
    "ratings = [Rating() for i in range(100)]\n",
    "for i in range(100):\n",
    "    choice = np.random.choice(teams,size=2,replace=True)\n",
    "    a = ratings[choice[0]]\n",
    "    b = ratings[choice[1]]\n",
    "    q = quality_1vs1(a, b)\n",
    "    wp = win_probability([a],[b])\n",
    "    print(wp)\n",
    "    a, b = ts.rate_1vs1(a, b, drawn=False)\n",
    "    \n",
    "    ratings[choice[0]] = a\n",
    "    ratings[choice[1]] = b\n",
    "\n",
    "mus = [r.mu for r in ratings]\n",
    "sigma = [r.sigma for r in ratings]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/5821125/how-to-plot-confusion-matrix-with-string-axis-rather-than-integer-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sudo apt-get install build-essentials gfortran gcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
