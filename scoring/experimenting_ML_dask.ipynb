{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "\n",
    "cluster = ipp.Client(profile='ssh')\n",
    "\n",
    "cluster.ids\n",
    "\n",
    "dview = cluster[:]\n",
    "dv = cluster[:]\n",
    "\n",
    "view = cluster.load_balanced_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(a,b):\n",
    "    return a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "async_results = []\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        # This line submits the tasks for parallel computation.\n",
    "        ar = view.apply_async(test, i,j)\n",
    "        async_results.append(ar)\n",
    "\n",
    "cluster.wait_interactive(async_results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "async_results = []\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        # This line submits the tasks for parallel computation.\n",
    "        ar = test(i,j)\n",
    "        async_results.append(ar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit dv.map_sync(lambda x, y, z: x + y + z, range(10), range(10), range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit cluster[0].map_sync(lambda x, y, z: x + y + z, range(10), range(10), range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "serial_result = map(lambda x:x**10, range(32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "parallel_result = dview.map_sync(lambda x: x**10, range(32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "serial_result==parallel_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbv = ipclient.load_balanced_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lbv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipclient.profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = cluster.become_dask()  # start dask on top of IPyParallel\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dclient = distributed.worker_client(ipclient)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dclient = dask_client_from_ipclient(ipclient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dask Client.get method computes dask graphs on the cluster.\n",
    "dclient.get({'a': 41, 'b': (lambda x: x + 1, 'a')}, 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dask Client.get method computes dask graphs on the cluster.\n",
    "dclient.get({'a': 41, 'b': (lambda x: x + 1, 'a')}, 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from time import sleep\n",
    "import random\n",
    "\n",
    "def inc(x):\n",
    "    sleep(random.random() / 10)\n",
    "    return x + 1\n",
    "\n",
    "def dec(x):\n",
    "    sleep(random.random() / 10)\n",
    "    return x - 1\n",
    "\n",
    "def add(x, y):\n",
    "    sleep(random.random() / 10)\n",
    "    return x + y\n",
    "\n",
    "\n",
    "client = Client('192.168.1.4:8786')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import sys, path\n",
    "sys.path.append(path.dirname(path.dirname(path.abspath('__file__'))))\n",
    "\n",
    "import pprint\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import h5py\n",
    "\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import os\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import matplotlib\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client, progress\n",
    "c = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final = dd.read_csv('./final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final = final.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final.result_final.value_counts().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# final['over_under_1.5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# final.set_index('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_data = pd.read_csv('../data/predict.csv', index_col='Unnamed: 0')\n",
    "df_teams = pred_data[['home_team','away_team']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_csv('./final.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht = final.home_team.values\n",
    "at = final.away_team.values\n",
    "all_teams = np.append(ht,at)\n",
    "un = np.unique(all_teams)\n",
    "un.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final.loc[:,'home_team'] = le.transform(final.home_team.values)\n",
    "final.loc[:,'away_team'] =  le.transform(final.away_team.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# del final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# result_key = 'over_under_2.5' \n",
    "result_key = 'result_final' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# final2 = final[(final.EH!=100) & (final.EA!=100)].iloc[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_out_100(data):\n",
    "    print('[Filter]')\n",
    "    dataf = data[(data.EH!=100) | (data.EA!=100)].iloc[:]\n",
    "    return dataf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_data_labels(data, labels=['1','X','2'], npoints=1000):\n",
    "    x = data.iloc[:npoints]['EH'].values\n",
    "    y = data.iloc[:npoints]['EA'].values\n",
    "    label = data.iloc[:npoints][result_key].values\n",
    "    colors = ['green','blue','black']\n",
    "\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    plt.scatter(x, y, c=label, cmap=matplotlib.colors.ListedColormap(colors))\n",
    "    plt.xlabel('EH')\n",
    "    plt.ylabel('EA')\n",
    "    cb = plt.colorbar()\n",
    "    loc = np.arange(0,max(label),max(label)/float(len(colors)))\n",
    "    cb.set_ticks(loc)\n",
    "    cb.set_ticklabels(labels)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x = final2['EH'].values\n",
    "y = final2['EA'].values\n",
    "label = final2['over_under_2.5'].values\n",
    "colors = ['green','black']\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.scatter(x, y, c=label, cmap=matplotlib.colors.ListedColormap(colors))\n",
    "plt.xlabel('EH')\n",
    "plt.ylabel('EA')\n",
    "cb = plt.colorbar()\n",
    "loc = np.arange(0,max(label),max(label)/float(len(colors)))\n",
    "cb.set_ticks(loc)\n",
    "cb.set_ticklabels(['over','under'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_pca(data):\n",
    "    print('[PCA]')\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "\n",
    "    # print(pca.explained_variance_ratio_)  \n",
    "\n",
    "    # print(pca.singular_values_)  \n",
    "\n",
    "    pca.fit(data.values[:,[2,3]])\n",
    "\n",
    "    tx =  pca.transform(data.values[:,[2,3]]) \n",
    "\n",
    "    data.loc[:,['EH','EA']] = tx\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(data):\n",
    "    print('[Classifier]')\n",
    "    X = data.iloc[:][['home_team','away_team','EH','EA']]#.values\n",
    "    # X = final.iloc[:][['EH','EA']]#.values\n",
    "    y = data.iloc[:][result_key]#.values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.75, test_size=0.25, random_state=42)\n",
    "\n",
    "    # final.iloc[:50000].tail()\n",
    "\n",
    "    clf = GaussianNB()\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "\n",
    "    print('Accuracy: ',clf.score(X_test, y_test))\n",
    "    # print(metrics.accuracy_score(clf.predict(X_test), y_test))\n",
    "    # clf.export('tpot_mnist_pipeline.py')\n",
    "\n",
    "    predictions = clf.predict(X_test)\n",
    "\n",
    "    pprint.pprint(metrics.classification_report(predictions, y_test))\n",
    "\n",
    "#     predicted = cross_val_predict(clf, X,y, cv=5)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipeline_func(data, fns):\n",
    "    return reduce(lambda a,x: x(a), fns, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fns = [filter_out_100,plot_data_labels, classify, run_pca, plot_data_labels, classify]\n",
    "# fns = [filter_out_100,plot_data_labels, run_pca, plot_data_labels]\n",
    "fns = [filter_out_100, run_pca, classify]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipeline_func(final,fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = filter_out_100(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf1 = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.iloc[:][['home_team','away_team','EH','EA']]#.values\n",
    "# X = final.iloc[:][['EH','EA']]#.values\n",
    "y = data.iloc[:][result_key]#.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.75, test_size=0.25, random_state=42)\n",
    "\n",
    "# final.iloc[:50000].tail()\n",
    "\n",
    "# clf = GaussianNB()\n",
    "clf1 = clf1.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy: ',clf1.score(X_test, y_test))\n",
    "# print(metrics.accuracy_score(clf.predict(X_test), y_test))\n",
    "# clf.export('tpot_mnist_pipeline.py')\n",
    "\n",
    "predictions1 = clf1.predict(X_test)\n",
    "pprint.pprint(metrics.classification_report(predictions1, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data1 = run_pca(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data1.iloc[:][['home_team','away_team','EH','EA']]#.values\n",
    "# X = final.iloc[:][['EH','EA']]#.values\n",
    "y = data1.iloc[:][result_key]#.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.75, test_size=0.25, random_state=42)\n",
    "\n",
    "# final.iloc[:50000].tail()\n",
    "\n",
    "# clf = GaussianNB()\n",
    "clf2 = clf2.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy: ',clf2.score(X_test, y_test))\n",
    "# print(metrics.accuracy_score(clf.predict(X_test), y_test))\n",
    "# clf.export('tpot_mnist_pipeline.py')\n",
    "\n",
    "predictions2 = clf2.predict(X_test)\n",
    "pprint.pprint(metrics.classification_report(predictions2, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def choose(p1,p2, key=[0,0]):\n",
    "    if p1==key[0]:\n",
    "        return p1\n",
    "    elif p2==key[1]:\n",
    "        return p2\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame(list(zip(predictions1,predictions2, y_test)), columns=['p1','p2','ytrue'])\n",
    "\n",
    "out1 = []\n",
    "for i, (ix, row) in enumerate(output_df.iterrows()):\n",
    "    out1.append(choose(row.p1,row.p2, key=[0, 0]))\n",
    "\n",
    "out2 = []\n",
    "for i, (ix, row) in enumerate(output_df.iterrows()):\n",
    "    out2.append(choose(row.p1,row.p2,key=[1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_df.loc[:, 'fil1'] = out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_df.loc[:, 'fil2'] = out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi3 = output_df[['fil1', 'fil2']].sum(axis=1).values.astype(int)\n",
    "\n",
    "output_df.loc[:,'fil3'] = fi3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "output_df['fil3'].value_counts()\n",
    "output_df[['fil1', 'fil2']].sum(axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(output_df.shape)\n",
    "output_df = output_df.dropna()\n",
    "print(output_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(metrics.accuracy_score(output_df['fil3'].values.astype(int), output_df['ytrue'].values.astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ytrue = output_df['ytrue'].values.astype(int)\n",
    "fi = output_df['fil3'].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pprint.pprint(metrics.classification_report(fi, ytrue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics.accuracy_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "# print(pca.explained_variance_ratio_)  \n",
    "\n",
    "# print(pca.singular_values_)  \n",
    "\n",
    "pca.fit(final2.values[:,[2,3]])\n",
    "\n",
    "tx =  pca.transform(final2.values[:,[2,3]]) \n",
    "\n",
    "final2.loc[:,['EH','EA']] = tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = final2['EH'].values\n",
    "y = final2['EA'].values\n",
    "label = final2['over_under_2.5'].values\n",
    "colors = ['green','black']\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.scatter(x, y, c=label, cmap=matplotlib.colors.ListedColormap(colors))\n",
    "plt.xlabel('EH')\n",
    "plt.ylabel('EA')\n",
    "cb = plt.colorbar()\n",
    "loc = np.arange(0,max(label),max(label)/float(len(colors)))\n",
    "cb.set_ticks(loc)\n",
    "cb.set_ticklabels(['over','under'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "final2['C_sign'] = np.sign(final2.EH)\n",
    "final2.groupby('over_under_3.5').C_sign.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NO PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final2 = final[(final.EH!=100) | (final.EA!=100)].iloc[:20000]\n",
    "\n",
    "final2.shape\n",
    "\n",
    "\n",
    "X = final2.iloc[:][['home_team','away_team','EH','EA']]#.values\n",
    "# X = final.iloc[:][['EH','EA']]#.values\n",
    "y = final2.iloc[:]['over_under_2.5']#.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.75, test_size=0.25, random_state=42)\n",
    "\n",
    "# final.iloc[:50000].tail()\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy: ',clf.score(X_test, y_test))\n",
    "# print(metrics.accuracy_score(clf.predict(X_test), y_test))\n",
    "# clf.export('tpot_mnist_pipeline.py')\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "pprint.pprint(metrics.classification_report(predictions, y_test))\n",
    "\n",
    "predicted = cross_val_predict(clf, X,y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# metrics.precision_score(y, predicted,pos_label=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with pca"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "final2['over_under_2.5'].value_counts(normalize=False).sort_index()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "final2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final2 = final[(final.EH!=100) | (final.EA!=100)].iloc[:20000]\n",
    "\n",
    "pca.fit(final2.values[:,[2,3]])\n",
    "\n",
    "tx =  pca.transform(final2.values[:,[2,3]]) \n",
    "\n",
    "final2.loc[:,['EH','EA']] = tx\n",
    "\n",
    "X = final2.iloc[:][['home_team','away_team','EH','EA']]#.values\n",
    "# X = final.iloc[:][['EH','EA']]#.values\n",
    "y = final2.iloc[:]['over_under_2.5']#.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.75, test_size=0.25, random_state=42)\n",
    "\n",
    "# final.iloc[:50000].tail()\n",
    "\n",
    "clf = GaussianNB()\n",
    "\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy: ',clf.score(X_test, y_test))\n",
    "\n",
    "# clf.export('tpot_mnist_pipeline.py')\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "pprint.pprint(metrics.classification_report(predictions, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X = final2.iloc[:][['home_team','away_team','EH','EA']]#.values\n",
    "# X = final.iloc[:][['EH','EA']]#.values\n",
    "y = final2.iloc[:]['over_under_2.5']#.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.75, test_size=0.25, random_state=42)\n",
    "\n",
    "# final.iloc[:50000].tail()\n",
    "\n",
    "tpot = TPOTClassifier(generations=1, population_size=13, verbosity=2)\n",
    "\n",
    "clf = tpot.fit(X_train, y_train)\n",
    "\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "clf.export('tpot_mnist_pipeline.py')\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "pprint.pprint(metrics.classification_report(predictions, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X = final2.iloc[:][['home_team','away_team','EH','EA']]#.values\n",
    "# X = final.iloc[:][['EH','EA']]#.values\n",
    "y = final2.iloc[:]['over_under_2.5']#.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.75, test_size=0.25, random_state=42)\n",
    "\n",
    "# final.iloc[:50000].tail()\n",
    "\n",
    "tpot = TPOTClassifier(generations=1, population_size=13, verbosity=2)\n",
    "\n",
    "clf = GaussianNB().fit(X_train, y_train)\n",
    "\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "clf.export('tpot_mnist_pipeline.py')\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "pprint.pprint(metrics.classification_report(predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# %load tpot_mnist_pipeline.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# NOTE: Make sure that the class is labeled 'target' in the data file\n",
    "tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)\n",
    "features = tpot_data.drop('target', axis=1).values\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, tpot_data['target'].values, random_state=42)\n",
    "\n",
    "# Score on the training set was:0.5814399904848592\n",
    "exported_pipeline = KNeighborsClassifier(n_neighbors=69, p=2, weights=\"distance\")\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X = final.iloc[:50000][['home_team','away_team','EH','EA']]#.values\n",
    "# # X = final.iloc[:][['EH','EA']]#.values\n",
    "# y = final.iloc[:50000]['over_under_2.5']#.values\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.75, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf1 = GaussianNB()\n",
    "clf1.fit(X_train, y_train)\n",
    "print(clf1.score(X_test, y_test))\n",
    "predictions1 = clf1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pprint.pprint(metrics.classification_report(predictions1, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf2 = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.1)\n",
    "clf2 = clf2.fit(X_train, y_train)\n",
    "predictions2 = clf2.predict(X_test)\n",
    "pprint.pprint(metrics.classification_report(y_test, predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(clf2.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load tpot_mnist_pipeline.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# NOTE: Make sure that the class is labeled 'target' in the data file\n",
    "tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)\n",
    "features = tpot_data.drop('target', axis=1).values\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, tpot_data['target'].values, random_state=42)\n",
    "\n",
    "# Score on the training set was:0.5522662309923989\n",
    "exported_pipeline = GaussianNB()\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = final.iloc[:10000][['home_team','away_team','EH','EA']]#.values\n",
    "y = final.iloc[:10000]['over_under_2.5']#.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.75, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Add noisy features\n",
    "random_state = np.random.RandomState(0)\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "# Create a simple classifier\n",
    "classifier = svm.LinearSVC(random_state=random_state)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_score = classifier.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_score,pos_label=0)\n",
    "\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                 color='b')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 0.2])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predictions = tpot.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from scipy import interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Binarize the output\n",
    "y = label_binarize(y, classes=[0, 1])\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "# Add noisy features to make the problem harder\n",
    "\n",
    "y_score = clf.decision_function(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aa = pd.DataFrame(list(zip(predictions,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = pd.DataFrame(y_train)\n",
    "a['over_under_2.5'].value_counts(normalize=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ys = aa[aa[0]!=0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yp = ys[:,0]\n",
    "yt = ys[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pprint.pprint(metrics.classification_report(yp, yt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load tpot_mnist_pipeline.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# NOTE: Make sure that the class is labeled 'target' in the data file\n",
    "tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)\n",
    "features = tpot_data.drop('target', axis=1).values\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, tpot_data['target'].values, random_state=42)\n",
    "\n",
    "# Score on the training set was:0.5523999202370016\n",
    "exported_pipeline = GaussianNB()\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = final.iloc[:][['home_team','away_team','EH','EA']].values\n",
    "y = final.iloc[:]['over_under_2.5'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.75, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.1)\n",
    "\n",
    "gbm.fit(X_train, y_train)\n",
    "\n",
    "predictions = gbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pprint.pprint(metrics.classification_report(predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ac = metrics.accuracy_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "conf_arr = metrics.confusion_matrix(predictions, y_test)\n",
    "\n",
    "norm_conf = []\n",
    "for i in conf_arr:\n",
    "    a = 0\n",
    "    tmp_arr = []\n",
    "    a = sum(i, 0)\n",
    "    for j in i:\n",
    "        tmp_arr.append(float(j)/float(a))\n",
    "    norm_conf.append(tmp_arr)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.clf()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_aspect(1)\n",
    "res = ax.imshow(np.array(norm_conf), cmap=plt.cm.jet, \n",
    "                interpolation='nearest')\n",
    "\n",
    "width, height = conf_arr.shape\n",
    "\n",
    "for x in range(width):\n",
    "    for y in range(height):\n",
    "        ax.annotate(str(conf_arr[x][y]), xy=(y, x), \n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center')\n",
    "\n",
    "cb = fig.colorbar(res)\n",
    "alphabet1 = ['Predicted-O','Predicted-U']\n",
    "alphabet2 = ['Actual-O','Actual-U']\n",
    "plt.xticks(range(width), alphabet2[:width])\n",
    "plt.yticks(range(height), alphabet1[:height])\n",
    "plt.savefig('confusion_matrix.png', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "digits = load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target,\n",
    "                                                    train_size=0.75, test_size=0.25)\n",
    "\n",
    "digits.data\n",
    "\n",
    "digits.target\n",
    "\n",
    "tpot = TPOTClassifier(generations=5, population_size=20, verbosity=2)\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "elohome\n",
    "\n",
    "ar_data[0].astype(int)\n",
    "\n",
    "dfs[1]\n",
    "\n",
    "ar_data = h5f[champ][team][:].T[r]\n",
    "\n",
    "ar_data\n",
    "\n",
    "tot = pd.concat(dfs, axis=0, ignore_index=False)\n",
    "\n",
    "tot\n",
    "\n",
    "h5f.close()\n",
    "\n",
    "len(outcomes)\n",
    "\n",
    "ypred\n",
    "metrics.recall_score(y_pred=ypred, y_true=ytrue, pos_label=0)\n",
    "\n",
    "ypred\n",
    "\n",
    "ytrue\n",
    "transformed_observed_data_elo_ratings.shape\n",
    "\n",
    "bob_says = transformed_observed_data_elo_ratings.reshape(-1,1)[-470:]\n",
    "model = model.fit(bob_says)\n",
    "transformed_observed_data_elo_ratings.reshape(-1, 1)[-10:]\n",
    "\n",
    "bob_says\n",
    "\n",
    "h5f.close()\n",
    "\n",
    "print(\"Bob said:\", \", \".join(map(lambda x: observations[int(x)], bob_says)))\n",
    "print(\"Alice Believes:\", \", \".join(map(lambda x: states[x], alice_hears)))\n",
    "h5f.close()\n",
    "pxx = transition_matrix_pxx(data=df.loc[htd.index]['result_final'].dropna().to_frame(),result='result_final',n_states=3)\n",
    "\n",
    "pyx = emission_probabilities_pyx(x_df=df.loc[htd.index]['result_final'].dropna().to_frame(),x_label='result_final',hidden_states=3,y_df=htd)\n",
    "\n",
    "px = df.loc[htd.index]['result_final'].value_counts(normalize=True).sort_index()\n",
    "\n",
    "px\n",
    "\n",
    "pxx\n",
    "\n",
    "\n",
    "df.loc[htd.index]['result_final'].dropna().to_frame()\n",
    "\n",
    "a = df[((df.home_team==teamh) & (df.away_team==teama)) | ((df.home_team==teama)&(df.away_team==teamh))]\n",
    "\n",
    "a\n",
    "\n",
    "l = pd.concat([ht,at],axis=1)\n",
    "\n",
    "l.plot()\n",
    "# l.loc[a.index].plot()\n",
    "\n",
    "pd.concat([htd,atd],axis=1).plot()\n",
    "\n",
    "pd.concat([ht,at],axis=1).plot()\n",
    "\n",
    "ht.plot()\n",
    "at.plot()\n",
    "\n",
    "# df.loc[995088]\n",
    "\n",
    "# df[((df.home_team==teams[i]) | (df.away_team==teams[i])) & (df.championship==champ)]\n",
    "\n",
    "# df.loc[2054071]\n",
    "\n",
    "import itertools\n",
    "import math\n",
    "import trueskill\n",
    "def win_probability(team1, team2):\n",
    "    delta_mu = sum(r.mu for r in team1) - sum(r.mu for r in team2)\n",
    "    sum_sigma = sum(r.sigma ** 2 for r in itertools.chain(team1, team2))\n",
    "    size = len(team1) + len(team2)\n",
    "    denom = math.sqrt(size * (BETA * BETA) + sum_sigma)\n",
    "    ts = trueskill.global_env()\n",
    "    return ts.cdf(delta_mu / denom)\n",
    "\n",
    "BETA = ts.BETA\n",
    "def win_probability(a, b):                                                      \n",
    "    deltaMu = sum([x.mu for x in a]) - sum([x.mu for x in b])                   \n",
    "    sumSigma = sum([x.sigma ** 2 for x in a]) + sum([x.sigma ** 2 for x in b])  \n",
    "    playerCount = len(a) + len(b)                                               \n",
    "    denominator = math.sqrt(playerCount * (BETA * BETA) + sumSigma)             \n",
    "    return cdf(deltaMu / denominator)  \n",
    "\n",
    "teams = np.arange(100)\n",
    "ratings = [Rating() for i in range(100)]\n",
    "for i in range(100):\n",
    "    choice = np.random.choice(teams,size=2,replace=True)\n",
    "    a = ratings[choice[0]]\n",
    "    b = ratings[choice[1]]\n",
    "    q = quality_1vs1(a, b)\n",
    "    wp = win_probability([a],[b])\n",
    "    print(wp)\n",
    "    a, b = ts.rate_1vs1(a, b, drawn=False)\n",
    "    \n",
    "    ratings[choice[0]] = a\n",
    "    ratings[choice[1]] = b\n",
    "\n",
    "mus = [r.mu for r in ratings]\n",
    "sigma = [r.sigma for r in ratings]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/5821125/how-to-plot-confusion-matrix-with-string-axis-rather-than-integer-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sudo apt-get install build-essentials gfortran gcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
